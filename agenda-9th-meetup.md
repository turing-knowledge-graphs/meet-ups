## 9th Meet-up of The Turing Interest Group on [Knowledge Graphs](https://www.turing.ac.uk/research/interest-groups/knowledge-graphs)

- **When:** May 20th 2024  (3:30pm-6pm BST)
- **Format:** in-person.
- **Where:** City, University of London, Lecture Theatre B200, [University Building](https://staffhub.city.ac.uk/timetabling/rooms-by-building/university-building/b200).  Directions to get to the [Lecture Theather B200](https://drive.google.com/file/d/1IZJJIYSBwjitvBUa8bKIZ38fEwwWK95f/view?usp=sharing).
- **Registration** via this [form](https://forms.office.com/e/ZyTtJdWVis) (only for in-person attendance).
- **Recording:** Link to [recording](https://echo360.org.uk/section/5e35847f-eb8f-4533-b886-f34fb4a0d601/public).

## Agenda

15:30-16:00    Coffee and Networking

16:00-17:00    Talk by [Juan Sequeda](https://juansequeda.com/), the Principal Scientist and Head of the AI Lab at [data.world](https://data.world/)

> **Title**:  Increasing the LLM Accuracy for Question Answering: Ontologies to the Rescue! (a follow up to his talk in [September](https://github.com/turing-knowledge-graphs/meet-ups/blob/main/agenda-7th-meetup.md)).
          
> **Abstract:**  There is increasing evidence that question-answering (QA) systems with Large Language Models (LLMs), which employ a knowledge graph/semantic representation of an enterprise SQL database (i.e. Text-to-SPARQL), achieve higher    accuracy compared to systems that answer questions directly on SQL databases (i.e. Text-to-SQL). The question remains: how can we further improve the accuracy?          
> Building on the observations of our previous benchmark work where the inaccurate LLM-generated SPARQL queries followed incorrect paths, we present our Ontology-based Query Check (OBQC) approach which 1) leverages the ontology of the knowledge graph to check if the LLM-generated SPARQL query matches the semantic of ontology to detect errors and 2) use the explanations of the errors with an LLM to repair the errors. Using the chat with the data benchmark, our primary finding is that our approach increases the overall accuracy to 72% including an additional 8% of unknown results. The overall error rate of 20%.  
> Furthermore, we will present the learnings from a series of customer hackathons on how to effectively build the knowledge graphs and set up the question answering systems.

> **Bio**: Juan Sequeda is the Principal Scientist and Head of the AI Lab at data.world. He holds a PhD in Computer Science from The University of Texas at Austin. Juan’s research and     industry work has been on the intersection of data and AI, with the goal to reliably create knowledge from inscrutable data, specifically designing and building Knowledge Graph for enterprise data and metadata management. Juan is the co-author of the book [“Designing and Building Enterprise Knowledge Graph”](https://www.amazon.com/Designing-Enterprise-Knowledge-Synthesis-Semantics/dp/1636391745) and the co-host of [Catalog and Cocktails, an honest, no-bs, non-salesy data podcast](https://data.world/podcasts/).

17:00-18:00    Networking
